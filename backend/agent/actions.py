from version_control.interface import Issue, VCClient
from agent.utils import parse_json_response, read_prompt_template
from logger import logger


def process_feature_request(request: Issue, client: VCClient, llm):
    prompt = read_prompt_template("feature_request")
    args = {
        "title": request.title,
        "description": request.description,
        "epics": [],
        "labels": [],
    }
    response = llm(prompt, args)

    logger.info(f"Issue proposal raw response:\n{response}")
    parsed_response = parse_json_response(response)
    logger.info(parsed_response)

    if parsed_response["solved"]:
        for issue in parsed_response["issues"]:
            logger.info(f"Creating issue:\n{issue}")
            print(f"label list {issue["labels"] + ["autogenerated"]}")
            client.post_new_issue(
                Issue(
                    title=issue["title"],
                    description=issue["description"],
                    state="open",
                    labels=issue["labels"] + ["autogenerated"],
                )
            )
            logger.info(f"Issue created successfully")

            if parsed_response["leave_comment"]:
                logger.info(f"Commenting on feature request...")
                client.add_comment_to_issue(request, parsed_response["extra_details"])
                logger.info(f"Commented successfully")

    else:
        suggestions = parsed_response["extra_details"]
        logger.info(
            f"LLM was unable to map feature request '{request.title}' to batch of issues. Details: {suggestions}"
        )
        logger.info(f"Commenting on feature request...")
        client.add_comment_to_issue(request, suggestions)
        logger.info(f"Commented successfully")


def process_feature_request_all(client: VCClient, llm):
    feature_requests = client.fetch_feature_requests()
    for r in feature_requests:
        process_feature_request(r, client, llm)
